{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12475735,"sourceType":"datasetVersion","datasetId":7871309}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics opencv-python","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile data.yaml\n\ntrain: /kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images\nval: /kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/valid/images\ntest: /kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/test/images\n\nnc: 17\nnames:\n  - 'Barefoots'\n  - 'Ear-protection'\n  - 'Harness'\n  - 'No_Ear-Protection'\n  - 'No_Glasses'\n  - 'Sandals'\n  - 'boots'\n  - 'face_mask'\n  - 'face_nomask'\n  - 'glasses'\n  - 'hand_glove'\n  - 'hand_noglove'\n  - 'head_helmet'\n  - 'head_nohelmet'\n  - 'person'\n  - 'shoes'\n  - 'vest'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T10:37:37.034389Z","iopub.execute_input":"2025-07-15T10:37:37.034953Z","iopub.status.idle":"2025-07-15T10:37:37.040386Z","shell.execute_reply.started":"2025-07-15T10:37:37.034925Z","shell.execute_reply":"2025-07-15T10:37:37.039539Z"}},"outputs":[{"name":"stdout","text":"Overwriting data.yaml\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!yolo detect train data=data.yaml model=yolov8n.pt epochs=10 imgsz=640 batch=16 device=0,1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T11:18:00.156297Z","iopub.execute_input":"2025-07-15T11:18:00.156984Z","iopub.status.idle":"2025-07-15T12:03:21.801048Z","shell.execute_reply.started":"2025-07-15T11:18:00.156954Z","shell.execute_reply":"2025-07-15T12:03:21.800025Z"}},"outputs":[{"name":"stdout","text":"New https://pypi.org/project/ultralytics/8.3.167 available üòÉ Update with 'pip install -U ultralytics'\nUltralytics 8.3.166 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n                                                        CUDA:1 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=0,1, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train4, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train4, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\nOverriding model.yaml nc=80 with nc=17\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    754627  ultralytics.nn.modules.head.Detect           [17, [64, 128, 256]]          \nModel summary: 129 layers, 3,014,163 parameters, 3,014,147 gradients, 8.2 GFLOPs\n\nTransferred 319/355 items from pretrained weights\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /usr/bin/python3 -m torch.distributed.run --nproc_per_node 2 --master_port 56587 /root/.config/Ultralytics/DDP/_temp_sasvsj33131961272156368.py\nUltralytics 8.3.166 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n                                                        CUDA:1 (Tesla T4, 15095MiB)\nOverriding model.yaml nc=80 with nc=17\nTransferred 319/355 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 38.5¬±17.2 MB/s, size: 54.1 KB)\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-1-1-1-1-mp40_jpg.rf.d01f57d39ddf7b0da68e999207153d2f.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-1-1-1-1-mp42_jpg.rf.283e69143e7c30f0faae2a0dff17362c.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-1-1-1-112_jpg.rf.59003700ede444f10f0295de3f9c564c.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-1-1-1-112_jpg.rf.7b39ff350b7ad1eccef20195f19337c7.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-1-1-1-11_jpg.rf.796fa0b13b7e648bc11b6aedad08fb96.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-1-1-1-11_jpg.rf.c9f7458ffd4a4770d8c74bd3b677059b.jpg: 6 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-1-1-1-210_jpg.rf.307a9c183e54ac5582f6de004339fa86.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-1-1-1-24_jpg.rf.9c03e2baeb5eda8eff83d92918d0c269.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-1-1-1-25_jpg.rf.52c580b840e2828a6d177340a663d843.jpg: 8 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-1-1-2-26_jpg.rf.f251d086a3a5a3f319345b31c6c8cf0a.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-1-1-3-212_jpg.rf.2967c3b66c1aba80fdcf12e242272b75.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-1-1-3-22_jpg.rf.4a9c35d10fccefafbedf4fdecb4aea45.jpg: 6 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-1-1-3-27_jpg.rf.dfb8a76bd03727a6bc27ede4c58ca6c5.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-1-1-4-11_jpg.rf.88b08b990d7ad98413df37c9db96a997.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-1-1-4-11_jpg.rf.a7256a2193ebdb227932c393ee3acd0a.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-1-1-4-24_jpg.rf.4e63cd60286c38ef9f842070d4eaf4b2.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-1-1-5-15_jpg.rf.c55dba1143d835415af18b01f7267113.jpg: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-1-1-5-23_jpg.rf.0b1e35362f005069ee0f7aed4d060da4.jpg: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-2-1-1-27_jpg.rf.342d7c85f308b15b7d86eed78721513d.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-2-1-1-28_jpg.rf.4ae3d97efe2dcd2ed556b1f768407267.jpg: 5 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-2-1-4-28_jpg.rf.86d3bbec936f3d4aab6556c6fe55939a.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-3-1-1-26_jpg.rf.9ef6d8d04656bd5ad2753c7838dbfe2a.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-3-1-2-35_jpg.rf.a80f1fa46b3b92146f7b1ac96c69d71b.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-3-1-5-29_jpg.rf.e7dc20dc5ab52fd8d0ca6851cb61ec07.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-5-1-2-110_jpg.rf.8deac143d2830e72ef7503498063c4b6.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-5-1-2-26_jpg.rf.2d258edb7ed3a3f823e43921b03c4e8f.jpg: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-1-5-1-4-212_jpg.rf.30a305d85a2a13f88d62ddf94ca95594.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-2-1-2-1-22_jpg.rf.1c23e6fc569cfc0c83bf01cd19145c4f.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-15-2-1-2-5-111_jpg.rf.6d22d1392e0c430f3a952980990ec41d.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-01-16-2-4-2-4-210_jpg.rf.302295294fde321ba502287948e2e1e1.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-2023-11-21-112049_png_jpg.rf.2dbebe60b28c20f33a83f3b0294089a9.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-3-_jpg.rf.b61c0cc3b81df0cfc50c3e5394d06e97.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-65-_png_jpg.rf.932b905083b012561b2b5ed3e84d6d95.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-Casual-Shoes-Summer-Outdoor-Slip-on-Slippers-Men-Shoes-footwear-jpg_640x640_jpg.rf.15c65fdf1e39379b64ee7e3daecbaf30.jpg: 9 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-_696_png.rf.306c69e7c2cc97baa8c108df17ed509d.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/-_jpg.rf.e8e1e7244b78b4db0168a1609f630f44.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/001113_jpg.rf.3e01f3e5b9d307fd3c991967665de0a9.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/001113_jpg.rf.478088f44c731862df0f1c8d091daaad.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/001113_jpg.rf.a5c4b1dd15c96e1d4d8f29a37df2b25d.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/001225_jpg.rf.00bf018a0611b265342e5783afc2709d.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/001225_jpg.rf.24f329d9876b720716b8a9952a3ba952.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/001225_jpg.rf.b5b9546da6dc06f13a022cf21e48829e.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/00270_jpg.rf.d93d6d4deb12c7da76076a84c7ea4f79.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/00420_jpg.rf.ea873313cd0ebe8ceb241497e83168a4.jpg: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/1003987-BLK_2048x2x_jpg.rf.02cb9d2c09bf722ab711278e20ab013e.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/1005_sample1_jpg.rf.d3d67254297f41065789c027ec8986f3.jpg: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/1007_sample0_jpg.rf.97415d08aff7f7323ec10f3661dc617b.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/1008_sample3_jpg.rf.7997e497a31a1057878b25268b9f4c5d.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/1012_sample0_jpg.rf.250441f17d984d26877ff33644442201.jpg: 6 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/104016_jpg.rf.006ac9f46175b850cc7764ee49920ff7.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/10_jpg.rf.7bbf70d1341d72153bec8384f3fc99eb.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/122950125e314285d87410add0636370_jpg.rf.a7e6d0488f1985ae81a0b31580de5e98.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/1434531004-35-_JPG_jpg.rf.4472dd49cd2b766c64cc2f683eee7bba.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/1434531004-90-_JPG_jpg.rf.536eef8e623a29602c5bfb24179b21ec.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/15194265605_9324dc744a_o_jpg.rf.3d90059ecb580af8e032dffd08196932.jpg: 9 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/1608523440598_90vfspuw508_jpg.rf.a60eee774abf1e4c6659966c38050868.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/1608614738652_bxjw77k6rp7_jpg.rf.924603420965638cbb013345fde198ae.jpg: 6 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/1608696316142_5pv9lw47wck_jpg.rf.cb43ff1686deba0a12c4f85e1bbd57c0.jpg: 6 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/1608716860340_y1kknqgttv9_jpg.rf.93f31737ff289042a225f7688b78f780.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/1608716916309_vjsmpm8ydn_jpg.rf.3ba78839645b17192992880e86ecda4f.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/1608780037821_zyt2is0kz5h_jpg.rf.2c46b11d28f996d45de5b91bb2b35a1d.jpg: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/1608784778036_r0o8kv25n3_jpg.rf.ad31769b821eeeeef57c896eacdf67a5.jpg: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/1608785031189_a7nof2hdn6_jpg.rf.2ccc9828726e7f6849b44207793d5cef.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/1608883857364_9iwr1bzhyl5_jpg.rf.80229c5fd7218120ee4bbdfa7e329b6d.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/1637910940559_fgkl0q83m5i_jpg.rf.4955a5ea94893f645e98b8bcfba4479e.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/19120_jpg.rf.2832c3df577e406c4dc8d56574ebea35.jpg: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/1_jpg.rf.66f92af482ce38baa1b2c1d6b3dcea35.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/1_jpg.rf.de77164d4b448ed5984e4315fd82f6da.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/1fede4d8-istockphoto-1368229608-612x612_jpg.rf.43cd80cc2ed6b85a6120a12468567a64.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/1fede4d8-istockphoto-1368229608-612x612_jpg.rf.aa2d61ad83ea96a96459985e4dc8e7a6.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/21177_jpg.rf.dc06677b687447c98af6a5c982bd8aec.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/27_png_jpg.rf.e7505f3d58061790cd138b2fa539b7a8.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/3620_jpg.rf.a1185d8b6831216888bafa23c72f872c.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/3_jpg.rf.634d6748e148837ebfdcc06077adb1ed.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/49816_jpg.rf.8a87dc7e0c64b3b5d491738e3b54e7de.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/4T1A5886_1024x1024_jpg.rf.5c369568ed0ed6041e8b5dcb859843fd.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/5603_jpg.rf.e18c9336b7c91b63d1e0cc15181a6da5.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/6_png_jpg.rf.6447695c1550c760a9bfa71c834e000e.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/72b7fa6b44ac4668a20cc10ff622a27f_jpg.rf.59ae8049b880e496ffadaba65f414441.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/89_jpg.rf.6e3f1452d544a68a8803de0e0ce1f2d1.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/9100_jpg.rf.14a55e0ff0a4ad178c08668384334185.jpg: 7 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/RICONS_Du_1_80_jpg.rf.b75f1345997718ca3f3618ed55760024.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/Screenshot-from-2022-12-08-12-20-30_png.rf.22efaec4bf60f177eb9f56fe7c178250.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/Video1_123_jpg.rf.2a0383375c4299852108b6badb6762d8.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/Video1_223_jpg.rf.0db9bf3b2dfbe7612f30ab004cb3eedf.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/Video1_223_jpg.rf.125b9e557ac77f0d835f6f6a95d08c3e.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/Video1_223_jpg.rf.4f4be77783916589433903aa8a9df2db.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/Video1_25_jpg.rf.8367fcb536639ff2e5a72b9077934969.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/Video2_167_jpg.rf.300d26d3e41afeaa6fdd15d58bf7291d.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/Video2_167_jpg.rf.7377691cac82f0fa2b90b94c5ef02bf4.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/Video2_167_jpg.rf.ed07240e7d2d402700d541efb1e87ed8.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/Video2_6_jpg.rf.5e75ad87a41af9933ada45cb4c89660d.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/Video3_43_jpg.rf.e4d2618a6d3e30637a34a490126fc567.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/abf6d40a-istockphoto-1202287024-612x612_jpg.rf.4a94cd319029ebe098f758ed6b10db43.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/ear-protection-1-_jpg.rf.8369f8df7631f7b42a6d97205ef08199.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/ft-501-fashion-tails-black-original-imafwyfy9sznkdxq-bb_jpeg.rf.0e56f5ddf1facc0efc1d9c5499cab46e.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/full-body-harness-3-_jpg.rf.ad3b6eff0aa2da954bd7166cce41db88.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/full-body-harness-59-_jpg.rf.4e2c2e86fcb8e861540b2540312f1e15.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-1051092562-612x612_jpg.rf.608ab124827bb0b4a193ea903989a22e.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-1051092562-612x612_jpg.rf.957ca628bcbf8614b40dca4a55183662.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-1051092562-612x612_jpg.rf.b9927a125f1054002f86c6ddde7de92c.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-106598600-612x612_jpg.rf.89637d2d64c46ee5f2d10aa0aac361c4.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-106598600-612x612_jpg.rf.a7725e7dfee6a12b12e400de28372a2d.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-106598600-612x612_jpg.rf.f0ce914ae365214f76b81bf662908a19.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-1146259213-612x612_jpg.rf.a37cb9721209999d3a4f9159009388dd.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-1146259213-612x612_jpg.rf.c58b377e2ca4911d2a692318b3bc0c06.jpg: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-1146259213-612x612_jpg.rf.c6cfed3c316d36a50f3987f03cc5f1cb.jpg: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-1297382944-612x612_jpg.rf.4d61f517015fd11931c2bb6c037974ef.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-1297382944-612x612_jpg.rf.5f4323e5498c5a7e51b23d2c18a357c8.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-1297382944-612x612_jpg.rf.cb519a1d65e8e32198f224beb496f29d.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-1302229856-612x612_jpg.rf.b89cfc3a0c5969a2404b3eb7cfe6c223.jpg: 6 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-1302229856-612x612_jpg.rf.cffd94cac9fd696010654fe9698e6079.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-1302229856-612x612_jpg.rf.dcbeb31eb6e7f2cc299efccf50bb3009.jpg: 6 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-1309473555-612x612_jpg.rf.72a1ab9ad7eec98ee5f9bec032b8ba74.jpg: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-1309473555-612x612_jpg.rf.bfa247b63b6c3810e62cf3bf215edb4b.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-1309473555-612x612_jpg.rf.dcaee5e4006d99b88979b7003f2c5e24.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-149319933-612x612_jpg.rf.2b0e2cb03428ea1e63710bd5b73162bb.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-149319933-612x612_jpg.rf.cd464833d2864f81b507a2345380219a.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-149319933-612x612_jpg.rf.f5664c32c49a80d434a30ab00ce30717.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-149320119-612x612_jpg.rf.240d6fd4a0307bfbe077d520971ce536.jpg: 7 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-149320119-612x612_jpg.rf.29d7a331c96dda77786941c549d66fd7.jpg: 5 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-149320119-612x612_jpg.rf.8767c75438479dcc2fbfce3cc8d27ce7.jpg: 9 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-508121319-612x612_jpg.rf.21131d80940e399df883589112ad6d68.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-508121319-612x612_jpg.rf.457fddf239930a0e8bc659469e4584d4.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-508121319-612x612_jpg.rf.64209e6a474da8327dfa6e9ef4847bba.jpg: 6 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-514366692-612x612_jpg.rf.6c32f15192c2abf718b3e32d8ec38c7e.jpg: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-514366692-612x612_jpg.rf.f9e5b06e998d262e47f22443f9cac80f.jpg: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-516012290-612x612_jpg.rf.1072ef227298a8411cefdb6c070769f6.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-516012290-612x612_jpg.rf.30add10c2cad696bd2f84faa05d9016a.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-516012290-612x612_jpg.rf.d49ebdaa954c0a7a76853418c0b5d055.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-691703536-612x612_jpg.rf.0e3960ee2af61a1173506c59bc05fccb.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-691703536-612x612_jpg.rf.759948f30c09ae9117cf112d4962886b.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-691703536-612x612_jpg.rf.db435f1dd5ee84b9790f08637b349bd9.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-807680780-612x612_jpg.rf.6b27b5fa7e895ba681cfbdee5888e7ed.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-807680780-612x612_jpg.rf.c39aed43a5e4c129c71cc2039ac2e32e.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-807680780-612x612_jpg.rf.cffdda45225d80748bac9acd828a1586.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-916731436-612x612_jpg.rf.4cb1fe65109500b175ef9dda6ec5b149.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-916731436-612x612_jpg.rf.ae29b471e1b73df861499d978154b84c.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-916731436-612x612_jpg.rf.e1b7bcaad9ffcdc683c574780e370e1c.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-950956144-612x612_jpg.rf.0118aba0f13fd807f403809332470d45.jpg: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-950956144-612x612_jpg.rf.3f935a9327167c8b626cac8e4f843bc5.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/gettyimages-950956144-612x612_jpg.rf.ba8e76badfca8313f71b0e3433c3a614.jpg: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/hard_hat_workers1041_png.rf.1d7372cb698a25bcc0336480c681008a.jpg: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/image_209_jpg.rf.06b4002494b1dbf38541344c6573786e.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/imagem_processada_1_jpg.rf.5c33212824cdee5ac2d699f1872d4ca9.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/images-14-_jpg.rf.5f953c6e5802a23ba82fe19887e6b586.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/images-14-_jpg.rf.7fcbefa1605bc3bdd63b556d1375ecf7.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/images172_jpg.rf.87a3c988463a031ebff7015439748996.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/images172_jpg.rf.c98d1a5f256e6f0edbe933bac097a0c1.jpg: 7 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/images254_jpg.rf.f0e8b95f92a5d93adf4e3c09eb9007c6.jpg: 5 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/images27_jpg.rf.d75234fcb95b13b146be0875e3b0b342.jpg: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/istockphoto-1040921246-612x612_jpg.rf.c325c156a0f79a8e3759fd38fc5ed2e5.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/istockphoto-1301543637-612x612_jpg.rf.0602568f4aaa2771f703c4c1da883c8f.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/istockphoto-92003976-612x612_jpg.rf.20775ce01cd3e701b2373c07b68a9a99.jpg: 5 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/youtube-109_jpg.rf.d2906848f52cf8bf5dd36d1e5c7f2025.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train/images/youtube-52_jpg.rf.849c4f137696732bd810d2a4dcfe3c86.jpg: 2 duplicate labels removed\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mtrain: \u001b[0mCache directory /kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/train is not writeable, cache not saved.\nWARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 41264, len(boxes) = 219348. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i\u001b[0m\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.4¬±0.8 ms, read: 42.6¬±18.9 MB/s, size: 51.5 KB)\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.y\u001b[0m\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i.yolov8/valid is not writeable, cache not saved.\nWARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 333, len(boxes) = 8996. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i\u001b[0mPlotting labels to runs/detect/train4/labels.jpg... \n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i\u001b[0m\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000476, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train4\u001b[0m\nStarting training for 10 epochs...\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i\u001b[0m\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/ppe-objection-detection/datasets/ppe detection.v3i\u001b[0m\n       1/10      1.35G      1.555      2.599      1.607          9        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1636       8996      0.537      0.522      0.518      0.289\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/10      1.67G      1.442       1.88      1.512         13        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1636       8996       0.62      0.574      0.584      0.335\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/10      1.69G        1.4      1.711      1.481         13        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1636       8996      0.639       0.61      0.619      0.361\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/10       1.7G      1.362       1.61      1.458         20        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1636       8996      0.673      0.623      0.646      0.381\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/10      1.72G      1.319      1.506      1.419         10        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1636       8996      0.685      0.654      0.665      0.396\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/10      1.73G      1.284       1.43      1.391         24        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1636       8996      0.666      0.683      0.678      0.412\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/10      1.75G      1.264      1.381      1.377         10        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1636       8996        0.7      0.691      0.709       0.43\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/10      1.77G      1.238      1.329      1.354         14        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1636       8996      0.713       0.69      0.718      0.439\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/10      1.79G      1.208       1.28      1.336         22        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1636       8996        0.7      0.722      0.726      0.448\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/10       1.8G      1.189       1.24      1.322         21        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all       1636       8996      0.719      0.714      0.734      0.456\n\n10 epochs completed in 0.720 hours.\nOptimizer stripped from runs/detect/train4/weights/last.pt, 6.2MB\nOptimizer stripped from runs/detect/train4/weights/best.pt, 6.2MB\n\nValidating runs/detect/train4/weights/best.pt...\nUltralytics 8.3.166 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n                                                        CUDA:1 (Tesla T4, 15095MiB)\nModel summary (fused): 72 layers, 3,008,963 parameters, 0 gradients, 8.1 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  m\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n                   all       1636       8996       0.72      0.715      0.735      0.456\n             Barefoots        172        327      0.861      0.914       0.95      0.668\n        Ear-protection        153        235      0.518      0.586      0.552       0.34\n               Harness        237        347      0.719      0.738      0.772      0.476\n     No_Ear-Protection        115        153       0.43       0.34       0.36      0.205\n            No_Glasses         80         95      0.494      0.568      0.482      0.244\n               Sandals        139        199      0.684      0.884      0.801      0.501\n                 boots        313        661       0.92       0.82      0.903      0.662\n             face_mask        309        399      0.733      0.797      0.748      0.384\n           face_nomask        359        563      0.753      0.726      0.783       0.39\n               glasses        328        401      0.757      0.739      0.742      0.411\n            hand_glove        449        830      0.774      0.657      0.672      0.392\n          hand_noglove        305        620      0.682      0.373      0.496      0.228\n           head_helmet        436        704      0.784      0.824      0.866      0.584\n         head_nohelmet        432        846      0.832      0.817      0.874      0.535\n                person        831       1488      0.782       0.88      0.895      0.697\n                 shoes        232        547      0.667       0.59      0.664      0.333\n                  vest        398        581      0.841      0.897      0.935      0.705\nSpeed: 0.2ms preprocess, 2.1ms inference, 0.0ms loss, 1.5ms postprocess per image\nResults saved to \u001b[1mruns/detect/train4\u001b[0m\nüí° Learn more at https://docs.ultralytics.com/modes/train\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}